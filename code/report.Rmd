---
title: "Missing Data - Assignment 1"
author: "Aga, Nisse, Ruben | Group 9"
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2
bibliography: references.bib  
---

```{r import dependencies, message = FALSE, warning = FALSE, echo = FALSE}
# We first specify our dependencies and read the data from the `data.rds` file.
library(tidyverse)
library(fastDummies)
library(kableExtra)
library(gridExtra, exclude="combine")
library(lubridate)
library(car)
library(ICC)
library(caret)
library(pROC)
library(naniar)
library(ggmice)
library(mice)
library(Hmisc)
library(vtable)
library(vcd)
```

```{r helper-functions, echo=FALSE}
show_table <- function(data, caption, scale = TRUE) {
  if (scale) {
    args <- c("striped", "scale_down", "hold_position", "repeat_header")
  } else {
    args <- c("striped", "hold_position", "repeat_header")
  }
  
  kbl(data, caption = caption, booktabs = T) %>%
    kable_styling(latex_options = args)
}
```

```{r load data, echo = FALSE}
source <- readRDS("../data/data.rds") %>%
  as_tibble()
```

```{r variable-selection, echo=FALSE}
# We create a sub-selection of variables that are of interest to our model.
data <- source %>%
  select(
    id,
    drink_regularly, 
    sex, 
    age,
    ethnicity, 
    education, 
    marital, 
    household_income,
    dep1,
    dep2,
    dep3,
    dep4,
    dep5,
    dep6,
    dep7,
    dep8,
    dep9
  ) %>%
  rename(income = household_income)
```

```{r set-seed. echo = FALSE}
set.seed(0)
```

\newpage

# Introduction
Alcohol consumption led to 2.8 million deaths in 2016 and accounts for almost 10% of global deaths in people aged 15-49 years. Higher levels of alcohol consumption leads to a higher risk of mortality and the only level of alcohol consumption that minimizes this risk is zero alcohol consumption (study). This means that drinking any alcohol at all increases the risk of mortality. All of this makes it vital to know and understand the factors behind alcohol consumption.

Moore et al. 2005 found that age, sex, ethnicity, marital status, education level and household income were all either negatively or positively associated with alcohol consumption. In Garnett et all. 2022 it was found that the level of depression was negatively associated with alcohol consumption. Considering that the only safe level of alcohol consumption is zero, it is important to understand what factors predict regular consumption of alcohol instead of only looking at the amount of alcohol consumption as in the two studies mentioned above. 

The research question of this study is: \textbf{Can the occurrence of regular alcohol consumption (12 or more in a year) be predicted by the variables: depression level, age, sex, ethnicity (white vs other), marital status and household income}. It is expected that age and depression level will be negatively correlated with the occurrence of alcohol consumption while household income will be positively correlated (sources). It is also expected that being male (vs female) and white ( vs other ethnicities) will be positively correlated with the regular occurrence of alcohol consumption (source). Regarding marital status it is expected that the married status will be positively associated with the regular occurrence of alcohol consumption compared to others but that is based on a study where the factor marital status consisted of just married and other (source), while in this study more categories are considered.

# Methodology (Aga)

## Dataset

The dataset used is a subset of the data collected in the National Health and Nutrition Examination Survey (NHANES). The survey is a part of annual program that investigates the health and nutrition of  a representative sample of people in the United States. The data we used contains information about 525 individuals that has been collected for the NHANES 2007-2008. This is a subset of the 12,946 individuals in that years' survey sample, out of which 78.4% was interviewed and 75.4% was examined in mobile examination centers. The NHANES is further subdivided into themed sections, such as the Alcohol Use questionnaire, that have separate documentation that will be referred to later. 

The used dataset contains a wide range of variables related, to the health of the individuals. We further subset the data by only including variables relevant to the study (demographics, alcohol use and answers to depression screener questions). The selected variables are further described in Variables Description section.  

## Variables Description

```{r, vars-desc, echo = FALSE}
# Read variable description file.
descs <- read.csv("../data/variables.csv", header = TRUE, sep = ";") %>%
  as_tibble()
show_table(descs, "Variable descriptions")
```

Table \@ref(tab:vars-desc) lists the variables used in our subset selection, which will be utilised for the model in question. 
The predictor variables $[dep1...dep9]$ are sourced from the same Depression Screener, where respondents of age 18 to 150 were ought to assign a number (1 to 3) regarding their mental and physical state within the last 2 weeks. Multiple signs of depression were measured this way, which can later be combined to indicate an overall level of depression.

The demographic variables - that being `sex`, `age`, `ethnicity`, `education` and `income` - were taken from the same screening component as well. The following should be noted, regarding these demographic variables:  

- The variable `age` is topcoded at the value `80`  for the respondents who were older than 80 years. 
- The variable `education` was targeted at respondents of age `20` to `150`, thus excluding younger participants. This is due to the fact that this question includes responses such as `AA degree` and `College Graduate`.
- Similarly, the variable `marital` was also targeted at respondents of age `20` to `150`.
- The variable `income` is ordinal, rather than continuous.  

As for the remaining demographic variables, namely `sex`, `age`, `ethnicity` and `income`, these are retrieved from target age `0` to `150`.  

Finally, the `drink_regularly` variable was obtained from an Alcohol Use questionnaire targeted at ages 20 and up.

## Data processing
After arriving at the subset dataset, as Exploratory Data Analysis was performed. The distributions of the variables were investigated and presence of missing data was found in the outcome variable and some of the depression questions. The important findings of this step are presented in 'EDA Results' section. 

Following the EDA, the missing data problem was addressed. The extend, distribution and patterns of missingness were investigated. Testing was done to verify the missing data mechanism, including testing of the dependencies between missing values in one variable and observed values of other variables and performing the Little (1988) MCAR Test. Since the assumptions of MCAR was not meet, MAR was assumed. 

Two solutions to the missing data problem were implemented: list-wise deletion and mean imputation. These where chosen based on the convenience of implementation. For list-wise deletion all cases with one or more missing values were excluded from the modeling. The mean imputation method was implemented in the following way: For the missing depression questions the mean of the observed values within the variable was computed and then the missing values were replaces by the mean value. This approach was taken, as in case of ordinal variables on Likert scale treating them as continuous is an appropriate (source). For 'drink_regularly, the outcome variable, instead of a mean, the mode was computed. This was motivated by the need for a binary outcome variable in the logistic regression that was planned to answer the research question. Since the EDA found there was significantly more 'yes' values than 'no' values in 'drink_regularly', the missing values were replaces by 'yes'. Thus, two complete datasets with different missing data treatments were created. 

Lastly, following the missing data treatments, the values for the depression questions were summed up to create an overall depression score for each individual. A sum was used, as opposed to other methods of aggregation (sucha as mean), as it preserves a convenient interpretation of a unit increase in a depression score. This overall score was used for modeling as opposed to the individual questions. 

## Modelling methodology
Including all of the variables in the two complete data sets is motivated by theoretical findings since other researchers found a relationship between them and drinking habits. Therefore, verifying the significance of these predictors and their relative importance in the presence of other variables was important. Thus, a decision was made to create two logistical models including all of the variables, instead of a top down or bottom up approach to model building. As opposed to removing the non-significant predictors as in the other approaches, we decided to keep them and therefore have more complex models. The two logistics models were then compared and the impact of the two different missing data treatments was evaluated.

# EDA Results (Nisse) {#EDA}

## Descriptive statistics {#desc-stats}

```{r data-calcs, echo=FALSE}
# Calculate frequency per marital category, excluding the dominant category of 'married'.
marital_counts <- data %>%
  select(marital) %>%
  filter(marital != 'married') %>%
  group_by(marital) %>%
  count()
  
# Calculate mean frequency of non-dominant marital categories.
marital_avg <- mean(marital_counts$n)

# Function for marital plotting
plot_marital <- function(data) {
  ggplot(data, aes(marital)) +
    geom_bar(stat = 'count') +
    labs(
      x = 'Marital status',
      y = 'Frequency'
    )
}
```
Table \@ref(tab:data-sum) from the appendix shows summary statistics for each of the variables within the dataset; including mean values, standard deviations, IQR statistics and data range values. For categorical variables, a list of possible categories and their respective proportions is provided to replace the continuous summary statistics. Lastly, the column `N` shows the amount of cases with present  data - that being non-NA values.  
In general, it is worthy to note that all variables are interpreted as a factor, excluding `age` and the multiple depression levels of `dep`. Table \@ref(tab:vars-desc) suggests that `dep` should in fact be categorical ordinal and should therefore be cast as a factor. That said - and as mentioned in Section \@ref(methodology) - keeping the levels of `dep` as a numerical continuous datatype is beneficial for our missing data problem.  

Our dichotomous outcome variable `drink_regularly` has 307 cases of "yes" and 107 cases of "no", having a outcome balance of 69% and 31% respectively. This outcome ratio could be considered imbalanced, which could affect the accuracy of our logistic regression model. Additionally, the total amount of value entries (`N`) of 446 suggests that 79 cases contain values outside of the set of possible binary values - most likely being missing values. Table \@ref(tab:drink-missing) further confirms this.  

```{r, drink-missing, echo=FALSE}
data %>%
  count(drink_regularly) %>%
  show_table("Drink regularly value distributions", scale = FALSE)
```

Predictor `sex` is a dichotomous variable with a balanced frequency distribution across the values "male" and "female", that being 48% and 52% respectively. 525 entries contain one of these values, suggesting that the variable does not contain missing data.  

The predictor `age` is the only continuous variable present within the sub-selected dataset. Although the survey was targeted at respondents of age 0-150 for most variables - the documentation even mentioning the topcoded entries for age 80+ - the dataset seems to only contain cases of people between the age of 20 and 69. Moreover, Figure \@ref(fig:age-dist) suggests a uniform distribution of the age variable.
Like `sex`, `age` has 525 cases with non-NA values, hence the variable does not contain missing data values.

```{r age-dist, fig.cap = "Distribution of age", echo=FALSE, warning=FALSE}
ggplot(data, aes(age)) +
  geom_histogram(stat = 'count') +
  labs(
      x = 'Age',
      y = 'Frequency'
    )
```

Predictor `ethnicity` has 5 categories, with `non-hispanic_white` being the most prevalant category with 220 cases (42% of total), all the while `other` is the most infrequent category with 25 cases (5%). A total of 525 cases contain `ethnicity` data, once again suggesting no presence of missing data values within this variable.  

Predictor `education` is similar to `ethnicity`, having 5 categories. That said, the frequencies of said categories seem to be less out of proportion, with `some_college` being the most frequent category with 155 (30%) cases. Whilst the data was retrieved from respondents of ages 20 and higher, we do not observe any missing data values within the variable. This can be further justified by the fact that the minimum `age` within our dataset is 20, therefore foregoing possible issues with younger participants being unable to provide data for this specific variable.

The predictor variable `marital` contains 6 categories. It should be noted that the category value `married` exceeds the average frequency of other categories (that being `r marital_avg`) by a large margin - as can be seen in Figure \@ref(fig:marital-dist-1). Specifically, 279 cases (53%) were `married`, with the other 5 categories made up the remaining 47% of the cases. `never_married` was the most frequent among those other 5 categories with 102 (19%) cases, whilst `separated` was the most infrequent category with only 14 (3%) cases. Furthermore, the meaning of `never_married` and `living_with_partners` is ambiguous in the sense that a person specifically living with their (non-married) partner can fall into both these categories.

```{r marital-dist-1, fig.cap = "Distribution of marital status categories before pre-processing", echo = FALSE}
plot_marital(data)
```

Predictor `income` is a ordinal variable formed by 12 levels, ranging from income values 0 to 100000+. This data, like `age`, is topcoded at the value 100000. This also explains the highest income category - that being 100000+ - having 76 cases (9%), as can be seen in Figure \@ref(fig:income-dist). If we ignore the latter case, the most frequent category is instead `25000:34999`, which coincidentally is the mid-range category of our income data.  
525 cases contain `income` data, therefore the variable does not contain missing data values.

```{r income-dist, fig.cap = "Distribution of income", echo = FALSE}
ggplot(data, aes(income)) +
  geom_histogram(stat = 'count') +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(
      x = 'Income',
      y = 'Frequency'
    )
```

The multiple levels of depression all have ranging scores between 0 and 3, with increments of 1 specifically. A higher score indicates agreement with the signs of depression described in the survey. Only `dep1` and `dep7` have complete data data, whilst the other levels have varying amounts of missing data. Missing data could possibly be caused by the respondents being reluctant to answers these questions. We also observe that `dep2`, `dep3`, `dep5`, `dep6` have the same amount of missing data value, hence it is plausible that they have a shared cause of missing data.
Lastly, `dep9` only has 18 cases of scores above 0, whilst also having the lowest mean value out of all depression levels. `dep9` describes the presence of suicidal thoughts, hence it makes sense that this has the lowest score out of all levels. On the contrary, `dep4` (feeling tired) has the highest average score.  
Overall, the score distribution are heavily skewed towards the 0 values.

## Outliers

For our only continuous predictor `age`, a boxplot shows potential outliers if datapoints fall outside of the interquartile range (whiskers of the plot). Figure \@ref(fig:age-outliers) shows the distribution of `age` in said boxplot, revealing no possible outliers. This is to be expected, since `age` was uniformly distributed as mentioned in Section \@ref(desc-stats).

```{r age-outliers, fig.cap = "Boxplot of age", echo=FALSE}
ggplot(data, aes(age)) +
  geom_boxplot()
```

Looking at the distributions of the various categorical variables, the `marital` showed the aforementioned imbalance in category frequencies.

## Correlations

Figure \@ref(fig:scatter-age) scatters the `age` data against the outcome variable `drink_regularly`. We observe that the "no" cases for `drink_regularly` tend to be of a higher age. The figure also reveals that the missing data entries for `drink_regularly` are generally younger respondents.

- mid class drinks less, poor and rich drink often.
- male drink more often
- 

```{r scatter-age, echo = FALSE}

ggplot(data, aes(age, drink_regularly, colour = drink_regularly)) +
  geom_jitter() +
  labs(x = 'Age', y = 'Drink regularly')

gg_miss_var(data, show_pct = TRUE)

ggmice(data, mapping = aes(age, drink_regularly)) + geom_jitter()

show_table(table(data$sex, data$drink_regularly), "")

show_table(table(data$ethnicity, data$drink_regularly), "")

show_table(table(data$education, data$drink_regularly), "")

show_table(table(data$marital, data$drink_regularly), "")

show_table(table(data$income, data$drink_regularly), "")
```

```{r cont-marital, echo = FALSE, warning = FALSE}
cont_mar <- table(data$marital, data$drink_regularly)
show_table(cont_mar, "Contigency table of marital vs. drink regularly", scale = FALSE)
```

TODO (from pract):  

- Variable with most NA's
- Summary of non-NA vars

# Missing data problem (Aga)

## Missing data and response Patterns
Firstly, we investigate the overall distribution of missing data in our dataset:

```{r mis-percentage, fig.cap = "Distribution of missing data in each variable", echo = FALSE}

# Creates a graph displaying the % of data missing in each variable
vis_miss(data)
```

As can be seen on Figure \@ref(fig:mis-percentage) , 8.2% of the data is missing. The missing values occur in the outcome variable 'drink_regularly' and in the responses to questions 'dep2', 'dep3', 'dep5', 'dep6', 'dep8' and 'dep9' that create the depression score variable. 15% of responses are missing for the predictor variable. 25% of the responses are missing for the individual depression questions 2, 3, 5 and 6, 10% are missing for question 8 and 14% for question 9. 

We further investigate the missing data patterns by looking at the response patters:

```{r res-pattern, fig.cap = "Response patterns and their frequency", echo = FALSE}
# Creates a graph with all of the response patterns in the dataset and their frequency
plot_pattern(data, rotate = TRUE)
```

Figure \@ref(fig:res-pattern) reveals that there are 13 distinct response patterns in the dataset and the missingness pattern is not monotone. The most frequent pattern is no missing entries, with 263 cases. It is important to note that the depression questions 2, 3, 5 and 6 are always either all present or all missing. It is very probable that the reason for item non-response for the depression items is the same, since there are no cases of only some of them missing. 

Based on the missingness pattern of the depression items, 41% of the overall depression score includes at least one missing value. 

## Missing data mechanism

Missing completly at random (MCAR) missingneses mechanism is often an important assumption for statistical analysis, including this one. To gain some inside whether the data is MCAR or not, we deploy a variety of tests. If missing values of a variable are MCAR then there should be no significant dependency of them with other variables. 

Firstly, Little MCAR test was preformed to verify if the missing data is MCAR at a global level, thus for all of the instances of missigness. The test was significant ($\chi^2 (164) = 465.18, p < 0.01$), therefore the data may be assumed as not MCAR. 
```{r mcar-test, echo = FALSE, include=FALSE}
mcar_test(data)
```

Since the data being MCAR can be questioned following the Little's test, a t-test was performed for all missing values vectors and numerical variables to check which variables are the likely culprit. The test compared the observed means of a given numerical variable within the group of individuals that had an observed value and the group with a missing value for another variable. Effectively testing if there is a significant difference in the continuous variable in the group that answered another question and the group that did not. Since the null hypothesis is no difference in means across the groups, a single significant value for a missingness of a given variable suggests that the missing values in that variable depend on the observed values of another variable. Therefore, it is likely that the missing values are not MCAR. Due to the identical pattern of responses in 'dep2', 'dep3', 'dep5' and 'dep6' it was sufficient to only test once for the dependency of their missing values. By the design of the test it is impossible to test the dependency of missing values and observed values within the same variable, thus these values are missing from the table. 

Assuming an alpha of 0.05, it can be observed that missing values of 'drink_regularly' are dependent on 'age', 'dep2' and 'dep9'. Similarly, 'dep2', 'dep3', 'dep5' and 'dep6' seem to be dependent on 'age' and the remaining depression questions. For missingness in 'dep8' and 'dep9' there are no significant differences across groups in any of the numerical variables. These tests suggest that at least 'drink_regularly', 'dep2', 'dep3', 'dep5' and 'dep6'are not MCAR, thus MAR will be assumed for them. In the table below the exact t-statistic and the p-value are reported. 

```{r is-mis-vectors, echo = FALSE}
# Creating vectors that indicate if a value is missing in a given variable. Since the pattern in depression items is the same, one vector is sufficient. 

mdrink <- is.na(data$drink_regularly)
mdep2 <- is.na(data$dep2)
mdep8 <- is.na(data$dep8)
mdep9 <- is.na(data$dep9)

# Testing dependency between missing value in var1 and values of var2. Null hypothesis: no dependency. 

dependency_test <- function(var, mis_vector){
  out <- t.test(var ~ mis_vector, data = data)
  paste(c("t =", paste(c(signif(out$statistic, digits = 3), ","), collapse =""), "pVal =", signif(out$p.value, digits = 3)), collapse = " ")

}

# make a table with outcomes of the t-test:
col1 <- c("age",
    "dep1",
    "dep2",
    "dep3",
    "dep4",
    "dep5",
    "dep6",
    "dep7",
    "dep8",
    "dep9")
col2 <- c(dependency_test(var = data$age, mis_vector = mdrink), dependency_test(var = data$dep1, mis_vector = mdrink), dependency_test(var = data$dep2, mis_vector = mdrink), dependency_test(var = data$dep3, mis_vector = mdrink), dependency_test(var = data$dep4, mis_vector = mdrink), dependency_test(var = data$dep5, mis_vector = mdrink), dependency_test(var = data$dep6, mis_vector = mdrink), dependency_test(var = data$dep7, mis_vector = mdrink), dependency_test(var = data$dep8, mis_vector = mdrink), dependency_test(var = data$dep9, mis_vector = mdrink))
col3 <- c(dependency_test(var = data$age, mis_vector = mdep2), dependency_test(var = data$dep1, mis_vector =  mdep2), "-", "-", dependency_test(var = data$dep4, mis_vector =  mdep2), "-", "-", dependency_test(var = data$dep7, mis_vector =  mdep2), dependency_test(var = data$dep8, mis_vector =  mdep2), dependency_test(var = data$dep9, mis_vector =  mdep2))
col4 <- c(dependency_test(var = data$age, mis_vector = mdep8), dependency_test(var = data$dep1, mis_vector =  mdep8), dependency_test(var = data$dep2, mis_vector =  mdep8), dependency_test(var = data$dep3, mis_vector =  mdep8), dependency_test(var = data$dep4, mis_vector =  mdep8), dependency_test(var = data$dep5, mis_vector =  mdep8), dependency_test(var = data$dep6, mis_vector =  mdep8), dependency_test(var = data$dep7, mis_vector =  mdep8), "-", dependency_test(var = data$dep9, mis_vector =  mdep8))
col5 <- c(dependency_test(var = data$age, mis_vector = mdep9), dependency_test(var = data$dep1, mis_vector =  mdep9), dependency_test(var = data$dep2, mis_vector =  mdep9), dependency_test(var = data$dep3, mis_vector =  mdep9), dependency_test(var = data$dep4, mis_vector =  mdep9), dependency_test(var = data$dep5, mis_vector =  mdep9), dependency_test(var = data$dep6, mis_vector =  mdep9), dependency_test(var = data$dep7, mis_vector =  mdep9), dependency_test(var = data$dep8, mis_vector =  mdep9), "-")

table_test <-as.data.frame(cbind(col1, col2, col3, col4, col5))

names(table_test) <- c("numerical variable", 
    "drink_regularly",
    "dep2/3/5/6",
    "dep8",
    "dep9")
show_table(as_tibble(table_test), "Dependency t-test: mean comparison in numerical variables across missing values and observed values in the other variables")


```


### Result models with deletion and imputation (Nisse)
- formula
- table with coefficients and pval (make sure to exponential the coefficients for easier interpretation)
- Interpretation of model result 

```{r}
miceOut <- mice(data, defaultMethod = c("norm.predict", "logreg", "polyreg", "polr"), m = 1, maxit = 1)
reg_imp_data <- complete(miceOut)
summary(reg_imp_data)
```

## Model creation (maybe combine with next section?)

Mostly code for now, will add more later on.  

TODO:  

- Use mode imputation for depression and outcome.
- Mention n rows removal in case of listwise

Summary of code:  
1. Create imputed data for each ad-hoc method.
2. combine deps levels for each dataset.
3. create models for analysis.

```{r combine-dep, echo = FALSE}
# Combine imputed levels of depression into one depression score.
combine_dep <- function(data) {
  data %>%
    mutate(dep = dep1 + dep2 + dep3 + dep4 + dep5 + dep6 + dep7 + dep8 + dep9) %>%
    select(-c(dep1, dep2, dep3, dep4, dep5, dep6, dep7,  dep8, dep9))
}
```

```{r mean-imp, echo = FALSE, warning = FALSE}
# Perform mean imputation on the data. Mode imputation is used for drink_regularly.

# Copy data
data_mi <- data

# Mode imputation for drink_regularly.
data_mi$drink_regularly <- impute(data_mi$drink_regularly, fun = mode)

# Mean imputation for depression levels.
data_mi <- mice(data_mi, method = "mean", m = 1, maxit = 1) %>%
  complete()

# Combine depression levels.
data_mi <- combine_dep(data_mi)

# Check if imputation works.
md.pattern(data_mi)
```

```{r lw-del, echo = FALSE}
# Perform listwise deletion on the data.
data_lw <- data[complete.cases(data), ]

# Combine depression levels.
data_lw <- combine_dep(data_lw)

# Check if imputation works.
md.pattern(data_mi)
```

```{r model-creation, echo = FALSE}
# Listwise deletion model creation.
fit_lw <- glm(
  drink_regularly ~ sex + age + ethnicity + education + marital + income + dep, 
  family = binomial, 
  data = data_lw
)

# Mean imputation model creation.
fit_mi <- glm(
  drink_regularly ~ sex + age + ethnicity + education + marital + income + dep, 
  family = binomial, 
  data = data_mi
)
```

## Comparison of the two diffrent models in terms of missing data treatment !!! (Ruben)
Depending on the chosen method used to treat the missing data, the answer on the research question changes. In the model fitted on the data where listwise-deletion was used as the missing data treatment only sex and marital status divorced were significant predictors (stats). Using mean imputation as the missing data treatment resulted in a fitted model where next to sex and marital status divorced, age and the intercept were also significant. The used method also changes the odds resulting from the model, in predictors that were significant in one but not the other ( see intercept for example) but also in predictors that were significant in both (see age and divorced). As can be seen the estimated odds differ quite a lot. The standard errors in the listwise deletion model are also considerably smaller than those in the mean imputation model. All of the above shows that the used missing data  treatment method can cause bias in the odds, standards errors and significant values. 

The missing data treatment method also influences the look of the resulting model as a whole. The model fitted on the listwise deletion data looks better, the null deviance and residual deviance are both considerably lower compared to the model fitted on the data resulting from mean imputation ( values ). Looking at AIC also gives the impression that the liswise deletion method gives a betger model.

To summarize the chosen method to treat the missing data causes bias in the individual predictors and in the look of the fitted model as a whole. As a result the answer to the studied research question depends on which method is chosen. 


## Conclusion in terms of answering RQ (Nisse)

- go back to papers, reflect hypo
- stuffs

# References

<div id="refs"></div>

# (APPENDIX) Appendix {-} 

# Appendix

```{r data-sum, echo=FALSE}
sumtable(data, title = "Summary statistics", fit.page = TRUE)
```
