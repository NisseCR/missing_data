---
title: "Missing Data - Assignment 1"
author: "Aga, Nisse, Ruben | Group 9"
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2
bibliography: references.bib  
---

```{r import-dependencies, message = FALSE, warning = FALSE, echo = FALSE}
library(tidyverse)
library(kableExtra)
library(naniar)
library(ggmice)
library(mice)
library(Hmisc)
library(vtable)
library(gtsummary)
```

```{r helper-functions, echo=FALSE}
# Pretty print of table.
show_table <- function(data, caption, scale = TRUE) {
  if (scale) {
    args <- c("striped", "scale_down", "hold_position", "repeat_header")
  } else {
    args <- c("striped", "hold_position", "repeat_header")
  }
  
  kbl(data, caption = caption, booktabs = T) %>%
    kable_styling(latex_options = args)
}

# Standard settings for correlatio plot (cat vs. cat)
cor_plot <- function(plot, name) {
  plot +
    geom_bar(stat = 'count', position = 'dodge') +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
    labs(x = name, y = 'Frequency')
}
```

```{r load-data, echo = FALSE}
source <- readRDS("../data/data.rds") %>%
  as_tibble()
```

```{r variable-selection, echo=FALSE}
# Create a sub-selection of variables that are of interest to our model.
data <- source %>%
  select(
    id,
    drink_regularly, 
    sex, 
    age,
    ethnicity, 
    education, 
    marital, 
    household_income,
    dep1,
    dep2,
    dep3,
    dep4,
    dep5,
    dep6,
    dep7,
    dep8,
    dep9
  ) %>%
  rename(income = household_income)
```

```{r relevel, echo = FALSE, warning = FALSE}
data$drink_regularly <- relevel(data$drink_regularly, "no")
```

```{r set-seed, echo = FALSE}
set.seed(0)
```

\newpage

# Introduction
Alcohol consumption led to 2.8 million deaths in 2016 and accounts for almost 10% of global deaths in people aged 15-49 years. Higher levels of alcohol consumption leads to a higher risk of mortality and the only level of alcohol consumption that minimizes this risk is zero alcohol consumption [@GBD]. This means that drinking any alcohol at all increases the risk of mortality. All of this makes it vital to know and understand the factors behind alcohol consumption.

Moore et al. 2005 found that age, sex, ethnicity, marital status, education level and household income were all either negatively or positively associated with alcohol consumption. In Garnett et all. 2022 it was found that the level of depression was negatively associated with alcohol consumption. Considering that the only safe level of alcohol consumption is zero, it is important to understand what factors predict regular consumption of alcohol instead of only looking at the amount of alcohol consumption as in the two studies mentioned above. 

The research question of this study is: \textbf{To what extent can the occurrence of regular alcohol consumption (12 or more in a year) be predicted by the variables: depression level, age, sex, ethnicity, marital status and household income?}  

It is expected that age and depression level will be negatively correlated with the occurrence of alcohol consumption, whilst household income will be positively correlated (sources). In addition, expectation entails that male (vs female) and white ( vs other ethnicities) will be positively correlated with the regular occurrence of alcohol consumption (source). Regarding marital status, it is expected that the married status will be positively associated with the regular occurrence of alcohol consumption compared to other marital statuses. That said, the latter was based on a study where the factor marital status consisted of just married and other [@moore], while in this study more categories were considered.

# Methodology

## Dataset

The dataset used was a subset of the data collected in the National Health and Nutrition Examination Survey (NHANES). The survey was a part of an annual program that investigated the health and nutrition of a representative sample of people in the United States. The data we used contained information about 525 individuals that were collected for the NHANES 2007-2008 survey. This was a subset of the 12,946 individuals in that years' survey sample, out of which 78.4% were interviewed whilst 75.4% participants were examined in mobile examination centers. The NHANES survey was further subdivided into themed sections - such as the Alcohol Use questionnaire - with each of these sections having separate documentations that will be referred to later on.

The used dataset contained a wide range of variables related to the health of the individuals. We further subsetted the data by only including variables relevant to the study (demographics, alcohol use and answers to depression screener questions). The selected variables are further described in Variables Description (Section \@ref(var-desc)).  

## Variables Description {#var-desc}

```{r, vars-desc, echo = FALSE}
# Read variable description file.
descs <- read.csv("../data/variables.csv", header = TRUE, sep = ";") %>%
  as_tibble()
show_table(descs, "Variable descriptions")
```

Table \@ref(tab:vars-desc) lists the variables used in our subset selection, which were utilised for the model in question. 
The predictor variables $[dep1...dep9]$ were sourced from the same Depression Screener, where respondents of age 18 to 150 were ought to assign a number (1 to 3) regarding their mental and physical state within the last 2 weeks. Multiple signs of depression were measured this way, which can be combined to create an overall depression score.  

The demographic variables - that being `sex`, `age`, `ethnicity`, `education` and `income` - were taken from the same screening component as well. The variable `age` was topcoded at the value `80`  for the respondents who were older than 80 years. Similarly, `education` was targeted at respondents of age `20` to `150`, thus excluding younger participants. This was due to the fact that this question included responses such as `AA degree` and `College Graduate`. The variable `marital` was also targeted at respondents of age `20` to `150`. Lastly, the variable `income` was ordinal, rather than continuous.  As for the remaining demographic variables, namely `sex`, `age`, `ethnicity` and `income`, these were retrieved from target age `0` to `150`. Finally, the `drink_regularly` variable was obtained from an Alcohol Use questionnaire targeted at ages 20 and up.

## Software

All of the data cleaning, processing and modeling was performed in R version 4.3.2 [@Rversion]. The following packages were used: *tidyverse* was used for data manipulation [@tidyverse], the *mice* [@mice] and *ggmice* [@ggmice] packaged were used for missing data visualizations and list-wise deletion and mean imputation, the *kableExtra* package was used for table styling [@kables], *naniar* package was used to make the visualization of missing data percentages (Figure \@ref(fig:mis-percentage)) [@nan], *Hmisc* was utilized for mode imputation, *vtable* helped with the summary statistic table in the Appendix [@vtab] and *gtsummary* was used to produce the summary tables for the two final models [@gtsummary].

## Data processing {#data-proc}
After arriving at the subset dataset, an Exploratory Data Analysis was performed. The distributions of the variables were investigated and the presence of missing data was found in the outcome variable and some of the depression questions. No outliers were found during the EDA. Additionally, the missingness seemed to be more prevalent among younger individuals, which gave a first indication of a lacking MCAR mechanism. The important findings of this step are presented in EDA Results (Section \@ref(EDA)). 

Following the EDA, the missing data problem was addressed. The extend, distributions and patterns of missingness were investigated. Testing was done to verify the missing data mechanism. This included performing a global test - Little MCAR test [@Little_1986] and testing of the dependencies between missing values in one variable vs. observed values of other variables. The latter was done using t-tests for continuous variables, whilst categorical variables were checked via Chi-squared test and Fisher test [@Soetewey]. The Fisher test with simulated p-values was used to verify outcomes for combinations of variables that included an expected frequency lower than 5, thus not meeting the assumptions of Chi-squared test [@Soetewey]. When the assumptions of MCAR was not met, MAR was assumed. 

Two solutions to the missing data problem were implemented: list-wise deletion and mean imputation. These where chosen based on the convenience of implementation. For list-wise deletion, all cases with one or more missing values were excluded from the modeling. Thus, the dateset was reduced by half to 263 observation. The mean imputation method was implemented in the following way: For the missing depression questions, the mean of the observed values within the variable was computed and then the missing values were replaced by said mean value. This approach was taken, since treating ordinal variables on a Likert scale as continuous variables instead was appropriate [@enders]. As found in the EDA (Section \@ref(desc-stats)), all of the depression item distributions are heavily skewed towards 0. Because of that,  '0.28', '0.53', '0.31', '0.20', '0.20' and '0.067' were imputed for 'dep2', 'dep3', 'dep5', 'dep6', 'dep8' and 'dep9' respectively. In turn, these low means even further skewed the distribution towards lower values. For `drink_regularly` - the outcome variable - the mode was computed rather than the mean. This was motivated by the need for a binary outcome variable in the logistic regression model that was utilized to answer the research question. The EDA suggested significantly more "yes" than "no" values in `drink_regularly`, hence the missing values were replaces by "yes". The 'drink_regularly' variable went from '397' 'yes' answers to '476', with '139' 'no' answers remaining unchanged. Therefore, after this data treatment the outcome ratio of the logistic regression was even more imbalanced, which could negatively affect the accuracy of the model. To conclude, two complete datasets with different missing data treatments were created. 

Lastly, following the missing data treatments, the values for the depression questions were summed up to create an overall depression score for each individual case. A sum was used - as opposed to other methods of aggregation (e.g. mean) - as it preserved a convenient interpretation of a unit increase in a depression score. This overall score was used for modeling as opposed to the individual depression levels. 

## Modelling methodology

Including all of the variables in the two complete data sets was motivated by theoretical findings, since other researchers found a relationship between them and drinking habits. Therefore, verifying the significance of these predictors and their relative importance in the presence of other variables was important. Thus, a decision was made to create two logistical models including all of the variables, instead of a top down or bottom up approach to model building. As opposed to removing the non-significant predictors following the aforementioned model-building methods, it was decided to keep all the predictor variables and therefore have a more complex model. Following model creation, the two logistics models were compared, where the impact of the two different missing data treatments was evaluated. For easier interpretation the model coefficients were exponentiated. Occurrence of regular drinking was considered the "successful" outcome.

# EDA Results {#EDA}

## Descriptive statistics {#desc-stats}

```{r data-calcs, echo=FALSE}
# Calculate frequency per marital category, excluding the dominant category of 'married'.
marital_counts <- data %>%
  select(marital) %>%
  filter(marital != 'married') %>%
  group_by(marital) %>%
  count()
  
# Calculate mean frequency of non-dominant marital categories.
marital_avg <- mean(marital_counts$n)

# Function for marital plotting
plot_marital <- function(data) {
  ggplot(data, aes(marital)) +
    geom_bar(stat = 'count') +
    labs(
      x = 'Marital status',
      y = 'Frequency'
    )
}
```
Table \@ref(tab:data-sum) in Appendix A shows summary statistics for each of the variables within the dataset; including mean values, standard deviations, IQR statistics and data range values. For categorical variables, a list of possible categories and their respective proportions was provided to replace the continuous summary statistics. Lastly, the column `N` shows the amount of cases with present  data - that being non-NA values.  
In general, we observed that all variables were interpreted as a factor, excluding `age` and the multiple depression levels of `dep`. Table \@ref(tab:vars-desc) suggested that `dep` should in fact be categorical ordinal and should therefore be cast as a factor. That said - and as mentioned in Section \@ref(data-proc) - keeping the levels of `dep` as a numerical continuous datatype was beneficial for our missing data problem.  

The dataset contained a total of 525 observations, each with 17 variables.  

The dichotomous outcome variable `drink_regularly` had 307 cases of "yes" and 107 cases of "no", having a outcome balance of 69% and 31% respectively. This outcome ratio could be considered imbalanced, which could affect the accuracy of our logistic regression model. Additionally, the total amount of value entries (`N`) of 446 suggested that 79 cases contained values outside of the set of possible binary values - most likely being missing values. Table \@ref(tab:drink-missing) further confirmed this.  

```{r, drink-missing, echo=FALSE}
data %>%
  count(drink_regularly) %>%
  show_table("Drink regularly value distributions", scale = FALSE)
```

Predictor `sex` was a dichotomous variable with a balanced frequency distribution across the values "male" and "female", that being 48% and 52% respectively. 525 entries contained one of these values, suggesting that the variable did not contain missing data.  

The predictor `age` was the only continuous variable present within the sub-selected dataset. Although the survey was targeted at respondents of age 0-150 for most variables - the documentation even mentioning the topcoded entries for age 80+ - the dataset seemed to only contain cases of people between the age of 20 and 69. Moreover, Figure \@ref(fig:age-dist) suggested a uniform distribution of the age variable.
Like `sex`, `age` had 525 cases of non-NA values, hence the variable did not contain missing data values.

```{r age-dist, fig.cap = "Distribution of age", echo=FALSE, warning=FALSE}
ggplot(data, aes(age)) +
  geom_histogram(stat = 'count') +
  labs(
      x = 'Age',
      y = 'Frequency'
    )
```

Predictor `ethnicity` had 5 categories, with `non-hispanic_white` being the most prevalent category with 220 cases (42% of total), all the while `other` was the most infrequent category with 25 cases (5%). A total of 525 cases contained `ethnicity` data, once again suggesting no presence of missing data values within this variable.  

Predictor `education` was similar to `ethnicity`, having 5 categories. That said, the frequencies of said categories seemed to be less out of proportion, with `some_college` being the most frequent category with 155 (30%) cases. Whilst the data was retrieved from respondents of ages 20 and higher, we did not observe any missing data values within the variable. This could be further justified by the fact that the minimum `age` within our dataset was 20, therefore foregoing possible issues with younger participants being unable to provide data for this specific variable.

The predictor variable `marital` contained 6 categories. It should be noted that the category value `married` exceeded the average frequency of other categories (that being `r marital_avg`) by a large margin, as can be seen in Figure \@ref(fig:marital-dist-1). Specifically, 279 cases (53%) were `married`, with the other 5 categories making up the remaining 47% of the cases. `never_married` was the most frequent among those other 5 categories with 102 (19%) cases, whilst `separated` was the most infrequent category with only 14 (3%) cases. Furthermore, the meaning of `never_married` and `living_with_partners` was ambiguous in the sense that a person specifically living with their (non-married) partner could fall into both these categories.

```{r marital-dist-1, fig.cap = "Distribution of marital status categories", echo = FALSE}
plot_marital(data)
```

Predictor `income` was an ordinal variable formed by 12 levels, ranging from income values 0 to 100000+. This data, like `age`, was topcoded at the value 100000. This also explained the highest income category - that being 100000+ - having 76 cases (9%), as can be seen in Figure \@ref(fig:income-dist). If we ignore the latter case, the most frequent category was instead `25000:34999`, which coincidentally was the mid-range category of our income data.  525 cases contained only observed `income` data, therefore the variable did not contain missing data values.

```{r income-dist, fig.cap = "Distribution of income", echo = FALSE, warning = FALSE}
ggplot(data, aes(income)) +
  geom_histogram(stat = 'count') +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(
      x = 'Income',
      y = 'Frequency'
    )
```

The multiple levels of depression all had ranging scores between 0 and 3, with increments of 1 specifically. A higher score indicated an agreement with the signs of depression described in the survey. Only `dep1` and `dep7` had complete data data, whilst the other levels had varying amounts of missing data. Missing data could possibly be caused by the respondents being reluctant to answers these questions. We also observed that `dep2`, `dep3`, `dep5`, `dep6` had the same amount of missing data values, hence it was possible that they had a shared cause of missing data.
Lastly, `dep9` only had 18 cases of scores above 0, whilst also having the lowest mean value out of all depression levels. `dep9` described the presence of suicidal thoughts, hence it made sense that this was the lowest average score out of all levels. On the contrary, `dep4` (feeling tired) had the highest average score.  Overall, the score distribution were heavily skewed towards the 0 values.

## Outliers

For our only continuous predictor `age`, a boxplot was utilised to find potential outliers . Figure \@ref(fig:age-outliers) shows the distribution of `age` in said boxplot, revealing no possible outliers. This was to be expected, since `age` was uniformly distributed as was mentioned in Section \@ref(desc-stats).

```{r age-outliers, fig.cap = "Boxplot of age", echo=FALSE}
ggplot(data, aes(age)) +
  geom_boxplot()
```

Looking at the distributions of the various categorical variables, the `marital` showed the aforementioned imbalance in frequency distribution, with the category `married` being overly dominant within the data. We considered combining the other `marital` categories into one, as their infrequency could allude to being possible outliers. Table \@ref(tab:cont-marital) shows the interrelations between the `martial` variable and our outcome `drink_regularly`. From this, we concluded that combining the remaining 5 categories - that being `widowed`, `divorced`, `separated`, `never_married` and `living_with_partner` - was not feasible, since these relations seemed to differ per category. For example, `widowed` had more "no" cases compared to "yes", whilst the relation was reversed for `separated`.

```{r cont-marital, echo = FALSE}
show_table(table(data$marital, data$drink_regularly), "Contingency table of marital status vs. drinking regularly", scale = FALSE)
```

## Correlations

```{r box-age, fig.cap = "Correlations of age vs. drink regularly", echo = FALSE}
ggplot(data, aes(age, drink_regularly, colour = drink_regularly)) +
  geom_boxplot()
```

Figure \@ref(fig:box-age) shows the distributions of `age` over the outcome variable `drink_regularly` in a boxplot. Not considering the NA values, `age` did not seem to be strongly correlated with `drink_regularly`, with "no" cases having only slightly higher ages than its counterpart.  It should however be noted that the NA values of `drink_regularly` were primarily present in younger participants, therefore possibly attenuating the correlation effect between these two variables. For example, a large amount of missing values belonging to "yes" could shift the distribution of these cases towards lower `age` values, hence increasing the difference in distributions for each `drink_regularly` outcome.  

Contingency tables and frequency distribution plots (including NA values) were used to observe the correlation between our categorical predictors and the outcome variable. From these, we observed that `sex` seemed to be highly correlated with `drink_regularly`; 172 cases of `male` drank regularly, whilst only 39 didn't. Compared to the 135 cases of `female` of "yes" and 100 cases of "no", this ratio seemed to differ greatly per `sex` category. The missingness of `drink_regularly` was evenly distributed across both `male` and `female` cases.  

<<<<<<< HEAD
Contingency tables and frequency distribution plots (including NA values) were used to observe the correlation between our categorical predictors and the outcome variable. From this, we observed that `sex` seemed to be highly correlated with `drink_regularly`; 172 cases of `male` drank regularly, whilst only 39 didn't. Compared to the 135 cases of `female` of "yes" and 100 cases of "no", this ratio seemed to differ greatly per `sex` category. The missingness of `drink_regularly` was evenly distributed across both `male` and `female` cases.

```{r cor-marital, fig.cap = "Correlations of marital vs. drink regularly", echo = FALSE, warning = FALSE}
cor_plot(ggplot(data, aes(marital, fill = drink_regularly)), 'Marital')
```

Likewise, `marital` showed a similarly strong correlation effect. The category `divorced` had a significantly higher ratio of respondents who drank regularly, compared to cases of `widowed`, where respondents were more likely to not drink regularly as can be seen in Figure \@ref(fig:cor-marital). We also noted that the missing data of `drink_regularly` was not evenly distributed across the `marital` categories. Rather, the missingness was more prevalent in the `never_married` and `living_with_partner` cases. This possibly ties back into the fact that more data was missing amongst younger respondents, which can be direcly seen in Figure \@ref(fig:age-marital) where `never_married` and `living_with_partner` have more cases of a younger age as well. 

```{r age-marital, fig.cap = "", echo = FALSE}
ggplot(data, aes(age, marital, colour = marital)) +
  geom_boxplot()
```

`ethnicity` showed a weaker correlation effect with the outcome variable. Only `non-hispanic_black` and `other` showed different frequency distributions compared to the other categories. Missing data of `drink_regularly` was present in all categories of `ethnicity`, though `other_hispanic` and `other` had close to none compared to the remaining categories.
The variable `education` was considered to have the weakest correlation with `drink_regularly`, having similar success ratios across all categories all the while missing data of `drink_regularly` was also evenly spread.  

`income` was considered to be correlated with the outcome variable. Performing a similar analysis, we observed that respondents with an income up until 24999 were less likely to drink regularly than cases with a higher income. Akin to `education`, missing data of `drink_regularly` seemed to be evenly spread across the `income` values.  

Finally, all levels of depression showed an effect of correlation with `drink_regularly`, where higher scores tended to decrease the ratio of "yes" to "no" cases, that is to say that respondents were less likely to drink regularly if signs of depression were present.

# Missing data problem

## Missing data and response patterns
Firstly, we investigated the overall distribution of missingness within our dataset.

```{r mis-percentage, fig.cap = "Distribution of missing data in each variable", echo = FALSE}
# Creates a graph displaying the % of data missing in each variable
vis_miss(data)
```

As can be seen on Figure \@ref(fig:mis-percentage), 8.2% of the data was missing. The missing values occurred in the outcome variable `drink_regularly` and in the responses to questions `dep2`, `dep3`, `dep5`, `dep6`, `dep8` and `dep9` that created the depression score variable. 15% of responses were missing for the predictor variable. 25% of the responses were missing for the individual depression questions 2, 3, 5 and 6, whilst 10% were missing for question 8. Finally, 14% of data was missing for question 9.  

```{r res-pattern, fig.cap = "Response patterns and their frequency", echo = FALSE}
# Creates a graph with all of the response patterns in the dataset and their frequency
plot_pattern(data, rotate = TRUE)
```

We further investigated the missing data patterns by looking at the response patterns. Figure \@ref(fig:res-pattern) reveals that there were 13 distinct response patterns in the dataset, with the missingness *not* being monotone. The most frequent pattern was no missing entries, with 263 cases. It is important to note that the depression questions 2, 3, 5 and 6 were always either all present or all missing. It is very probable that the reason for the item non-response regarding these depression levels was the same, since there were no cases with partial missingness in these 4 variables.  

Based on the missingness pattern of the depression items, 41% of the overall depression score included at least one missing value. 

## Missing data mechanism {#MDM}

Missing completely at random (MCAR) missingness mechanism is often an important assumption for statistical analysis, including this one. To gain some inside whether the data was MCAR or not, we deployed a variety of tests. If missing values of a variable was MCAR, said variable should not have a significant dependency with other (observed) variables.

Firstly, Little MCAR test was performed to verify if the missing data was MCAR at a global level, thus for all of the instances of missingess. The test was significant ($\chi^2 (164) = 465.18, p < 0.01$), therefore the data was assumed to *not* be MCAR.

```{r mcar-test, echo = FALSE, include=FALSE}
mcar_test(data)
```

Since the data being MCAR can be questioned following the Little's test, a t-test was performed for all missing values vectors and numerical variables to check which variables were the likely culprit. The test compared the observed means of a given numerical variable within the group of individuals that had an observed value and the group with a missing value for another variable. Effectively testing if there is a significant difference in the continuous variable in the group that answered another question and the group that did not. Since the null hypothesis suggests no difference in means across the groups, a single significant value for a missingness of a given variable suggests that the missing values in that variable depend on the observed values of another variable. Therefore, it is likely that the missing values are not MCAR. Due to the identical pattern of responses in `dep2`, `dep3`, `dep5` and `dep6` it was sufficient to only test once for the dependency of their missing values. By the design of the test, it was impossible to test the dependency of missing values and observed values within the same variable, thus these values were missing from the table. 

Assuming an alpha of 0.05, it was observed that missing values of `drink_regularly` were dependent on `age`, `dep2` and `dep9`. Similarly, `dep2`, `dep3`, `dep5` and `dep6` seemed to be dependent on `age` and the remaining depression questions. For missingness in `dep8` and `dep9`, there were no significant differences across groups in any of the numerical variables. These tests suggested that at least `drink_regularly`, `dep2`, `dep3`, `dep5` and `dep6` were not MCAR, thus MAR was assumed for them. In Table \@ref(tab:is-mis-vectors) the exact t-statistic and the p-value are reported. 

```{r is-mis-vectors, echo = FALSE}
# Creating vectors that indicate if a value is missing in a given variable. Since the pattern in depression items is the same, one vector is sufficient. 
mdrink <- is.na(data$drink_regularly)
mdep2 <- is.na(data$dep2)
mdep8 <- is.na(data$dep8)
mdep9 <- is.na(data$dep9)

# Testing dependency between missing value in var1 and values of var2 with t-test. Null hypothesis: no dependency. 
dependency_test <- function(var, mis_vector){
  out <- t.test(var ~ mis_vector, data = data)
  paste(c("t =", paste(c(signif(out$statistic, digits = 3), ","), collapse =""), "pVal =", signif(out$p.value, digits = 3)), collapse = " ")
}

# Make a table with outcomes of the t-test:
col1 <- c("age",
    "dep1",
    "dep2",
    "dep3",
    "dep4",
    "dep5",
    "dep6",
    "dep7",
    "dep8",
    "dep9")
col2 <- c(dependency_test(var = data$age, mis_vector = mdrink), dependency_test(var = data$dep1, mis_vector = mdrink), dependency_test(var = data$dep2, mis_vector = mdrink), dependency_test(var = data$dep3, mis_vector = mdrink), dependency_test(var = data$dep4, mis_vector = mdrink), dependency_test(var = data$dep5, mis_vector = mdrink), dependency_test(var = data$dep6, mis_vector = mdrink), dependency_test(var = data$dep7, mis_vector = mdrink), dependency_test(var = data$dep8, mis_vector = mdrink), dependency_test(var = data$dep9, mis_vector = mdrink))
col3 <- c(dependency_test(var = data$age, mis_vector = mdep2), dependency_test(var = data$dep1, mis_vector =  mdep2), "-", "-", dependency_test(var = data$dep4, mis_vector =  mdep2), "-", "-", dependency_test(var = data$dep7, mis_vector =  mdep2), dependency_test(var = data$dep8, mis_vector =  mdep2), dependency_test(var = data$dep9, mis_vector =  mdep2))
col4 <- c(dependency_test(var = data$age, mis_vector = mdep8), dependency_test(var = data$dep1, mis_vector =  mdep8), dependency_test(var = data$dep2, mis_vector =  mdep8), dependency_test(var = data$dep3, mis_vector =  mdep8), dependency_test(var = data$dep4, mis_vector =  mdep8), dependency_test(var = data$dep5, mis_vector =  mdep8), dependency_test(var = data$dep6, mis_vector =  mdep8), dependency_test(var = data$dep7, mis_vector =  mdep8), "-", dependency_test(var = data$dep9, mis_vector =  mdep8))
col5 <- c(dependency_test(var = data$age, mis_vector = mdep9), dependency_test(var = data$dep1, mis_vector =  mdep9), dependency_test(var = data$dep2, mis_vector =  mdep9), dependency_test(var = data$dep3, mis_vector =  mdep9), dependency_test(var = data$dep4, mis_vector =  mdep9), dependency_test(var = data$dep5, mis_vector =  mdep9), dependency_test(var = data$dep6, mis_vector =  mdep9), dependency_test(var = data$dep7, mis_vector =  mdep9), dependency_test(var = data$dep8, mis_vector =  mdep9), "-")

table_test <-as.data.frame(cbind(col1, col2, col3, col4, col5))

names(table_test) <- c("numerical variable", 
    "missing drink_regularly",
    "missing dep2/3/5/6",
    "missing dep8",
    "missing dep9")
show_table(as_tibble(table_test), "Dependency t-test: mean comparison in numerical variables across missing values and observed values in the other variables")
```

```{r chi-squared-test, warning = FALSE, echo = FALSE}
# Testing dependency between missing value in var1 and values of var2 with t-test. Null hypothesis: no dependency. 
dependency_chitest <- function(var, mis_vector){
  out <- chisq.test(table(var, mis_vector))
  paste(c("X^2 =", paste(c(signif(out$statistic, digits = 3), ","), collapse =""), "pVal =", signif(out$p.value, digits = 3)), collapse = " ")
}

# Make a table with outcomes of the chi-squared:
col1 <- c("drink_regularly",
    "sex",
    "ethnicity",
    "education",
    "marital",
    "income")
col2 <- c("-", dependency_chitest(var = data$sex, mis_vector = mdrink), dependency_chitest(var = data$ethnicity, mis_vector = mdrink), dependency_chitest(var = data$education, mis_vector = mdrink), dependency_chitest(var = data$marital, mis_vector = mdrink), dependency_chitest(var = data$income, mis_vector = mdrink))
col3 <- c(dependency_chitest(var = data$drink_regularly, mis_vector = mdep2), dependency_chitest(var = data$sex, mis_vector =  mdep2), dependency_chitest(var = data$ethnicity, mis_vector = mdep2), dependency_chitest(var = data$education, mis_vector =  mdep2), dependency_chitest(var = data$marital, mis_vector =  mdep2), dependency_chitest(var = data$income, mis_vector =  mdep2))
col4 <- c(dependency_chitest(var = data$drink_regularly, mis_vector = mdep8), dependency_chitest(var = data$sex, mis_vector =  mdep8), dependency_chitest(var = data$ethnicity, mis_vector =  mdep8), dependency_chitest(var = data$education, mis_vector =  mdep8), dependency_chitest(var = data$marital, mis_vector =  mdep8), dependency_chitest(var = data$income, mis_vector =  mdep8))
col5 <- c(dependency_chitest(var = data$drink_regularly, mis_vector = mdep9), dependency_chitest(var = data$sex, mis_vector =  mdep9), dependency_chitest(var = data$ethnicity, mis_vector =  mdep9), dependency_chitest(var = data$education, mis_vector =  mdep9), dependency_chitest(var = data$marital, mis_vector =  mdep9), dependency_chitest(var = data$income, mis_vector =  mdep9))

table_test2 <-as.data.frame(cbind(col1, col2, col3, col4, col5))

names(table_test2) <- c("categorical variable", 
    "missing drink_regularly",
    "missing dep2/3/5/6",
    "missing dep8",
    "missing dep9")

show_table(table_test2, "Independency Chi-squared test")
```

Since the t-test was not appropriate for categorical variables, we performed the Chi-squared test for said variables. The null hypothesis of the tests entailed no significant relationships between the categorical variables. The test compared observed frequencies to expected frequencies, if there was no relationship between the variables.

The outcomes of the test are presented in Table \@ref(tab:chi-squared-test). However, only `martial` with missingness of `drink_regularly` and `marital` with missingness of `dep2`, `dep3`, `dep5` and `dep6` were significant. Thus, it further supported the non-MCAR behaviour of missing data in these items. 

However, the Chi-squared test had an requirement that the smallest expected frequencies had to be higher than 5. This requirement was not met for some combinations of missing values and categorical variables. Specifically:  missing `dep8/9` and `ethnicity`, `marital`, `income`; missing `dep2/3/5/6` and `marital`, `income`; missing `drink_regularly` and `ethnicity`, `marital`, `income`. Since this assumption was not met for these combination, the p-values might not have been correctly estimated. Therefore, the Fischer test - which has the same hypothesis, but not the same assumption -  was performed for these combinations. 

```{r fisher-test, warning = FALSE, echo = FALSE}
# Testing dependency between missing value in var1 and values of var2 with fisher test. Null hypothesis: independent variables. 

dependency_fitest <- function(var, mis_vector){
  out <- fisher.test(table(var, mis_vector), simulate.p.value=TRUE,B=1e5)
  paste(c("pVal =", signif(out$p.value, digits = 3)), collapse = " ")
}

# make a table with outcomes of the fisher test:
col1 <- c("ethnicity",
    "marital",
    "income")
col2 <- c(dependency_fitest(var = data$ethnicity, mis_vector = mdrink), dependency_fitest(var = data$marital, mis_vector = mdrink), dependency_fitest(var = data$income, mis_vector = mdrink))
col3 <- c("-", dependency_fitest(var = data$marital, mis_vector = mdep2), dependency_fitest(var = data$income, mis_vector = mdep2))
col4 <- c(dependency_fitest(var = data$ethnicity, mis_vector = mdep8), dependency_fitest(var = data$marital, mis_vector = mdep8), dependency_fitest(var = data$income, mis_vector = mdep8))
col5 <- c(dependency_fitest(var = data$ethnicity, mis_vector = mdep9), dependency_fitest(var = data$marital, mis_vector = mdep9), dependency_fitest(var = data$income, mis_vector = mdep9))

table_test3 <-as.data.frame(cbind(col1, col2, col3, col4, col5))

names(table_test3) <- c("categorical variable", 
    "missing drink_regularly",
    "missing dep2/3/5/6",
    "missing dep8",
    "missing dep9")

show_table(table_test3, "Fisher test")

```
  
The outcomes of the Fisher test are presented in Table \@ref(tab:fisher-test). Like in the case of Chi-squared test, only `martial` with missingness of `drink_regularly` and `marital` with missingness of `dep2`, `dep3`, `dep5` and `dep6` were significant. Therefore, we concluded the dependence of missingness in these variables on multiple other observed variables and rejected MCAR in their case.

In all of the tests above, `dep8` and `dep9` did not seem to be dependent on any of the observed variables. Thus, perhaps MCAR could be assumed for these variables. However, since the depression scores will be collapsed into a single depression score ('dep') and other depression questions were MAR, the overall score was also assumed to be MAR.

# Modelling

## Interpretation of the two models {#interpret}

```{r combine-dep, echo = FALSE}
# Combine imputed levels of depression into one depression score.
combine_dep <- function(data) {
  data %>%
    mutate(dep = dep1 + dep2 + dep3 + dep4 + dep5 + dep6 + dep7 + dep8 + dep9) %>%
    select(-c(dep1, dep2, dep3, dep4, dep5, dep6, dep7,  dep8, dep9))
}
```

```{r mean-imp, echo = FALSE, warning = FALSE, message = FALSE, results = 'hide'}
# Perform mean imputation on the data. Mode imputation is used for drink_regularly.

# Copy data
data_mi <- data

# Mode imputation for drink_regularly.
data_mi$drink_regularly <- impute(data_mi$drink_regularly, fun = mode)

# Mean imputation for depression levels.
data_mi <- mice(data_mi, method = "mean", m = 1, maxit = 1) %>%
  complete()

# Combine depression levels.
data_mi <- combine_dep(data_mi)
```

```{r lw-del, echo = FALSE}
# Perform listwise deletion on the data.
data_lw <- data[complete.cases(data), ]

# Combine depression levels.
data_lw <- combine_dep(data_lw)
```

```{r model-creation, echo = FALSE}
# Listwise deletion model creation.
fit_lw <- glm(
  drink_regularly ~ sex + age + ethnicity + education + marital + income + dep, 
  family = binomial, 
  data = data_lw
)

# Mean imputation model creation.
fit_mi <- glm(
  drink_regularly ~ sex + age + ethnicity + education + marital + income + dep, 
  family = binomial, 
  data = data_mi
)
```

```{r model-compare, echo = FALSE}
# Obtain residual deviance statistic from model.
RD <- function(model) {
  summary(model)$deviance
}

# Create AIC, BIC and D table for all the models.
comp_df <- data.frame(
  model = c('listwise deletion', 'mean imputation'),
  AIC = c(AIC(fit_lw), AIC(fit_mi)),
  BIC = c(BIC(fit_lw), BIC(fit_mi)),
  D = c(RD(fit_lw), RD(fit_mi))
)

show_table(comp_df, caption = "Model fit statistics", scale = FALSE)
```

Two logistic models were created, one for each of the imputed datasets that resulted from both the ad-hoc mean imputation and listwise deletion missing  data methods. The interpretation below only includes significant predictors, since most of the model's predictors were non-significant. That said, they are still reported in the model summary tables, as can be seen Table \@ref(tab:lw-model) and Table \@ref(tab:mi-model) in Appendix A.
  
Looking at the listwise deletion model, only sex ( p < 0.001) and the marital category `divorced` (p <  0.001) were significant predictors, whilst all the other predictors (including the intercept) were insignificant. The odds ratio of females drinking regularly compared to males was 0.16[0.08, 0.31], meaning they were 0.16 times as likely to drink regularly compared to males. The odds ratio of `divorced` respondents compared to those who were `married` was 7.37[2.54, 25.0], meaning divorced people were 7.37 times as likely to drink regularly compared to married people. 

In the mean imputation model, `age` (p < 0.001) was also a significant predictor. This was in addition to `sex` (p < 0.001) and marital status `divorced` (p < 0.004 ). Moreover, the `intercept` (p < 0.001) was also significant. For a unit increase in age the odds ratio of drinking regularly decreases 0.97[0.95, 0.99] times. The odds ratio of females drinking regularly compared to males was 0.24[0.14, 0.38], meaning they were 0.24 times as likely to drink compared to males. The odds ratio of people with the marital status `divorced` compared to people with the marital status `married` was 3.05[1.47, 6.69], meaning divorced people were 3.05 times as likely to drink regularly compared to married people. If all predictor variables were in their reference state, the baseline odds ratio was 20.5[3.40, 136]. 
Looking at the model fit statistics, the listwise deletion model performed better with a lower AIC, BIC and $D$ value, as is shown in Table \@ref(tab:model-compare). 

## Results comparison ad-hoc methods

Following Section \@ref(interpret), the answer to the research question will differ depending on the ad-hoc method used to treat the missing data. Said difference is comprised of: the number of significant predictors, the odds ratios, standard errors and the fitness statistics. The SE of the mean imputation model was lower than the listwise deletion model, which can be see in Table \@ref(tab:mi-model) and \@ref(tab:lw-model).  
We concluded that the missing data treating methods caused biased results within each model, since these methods assume the missingness to be MCAR. This assumption does not hold, in case we assume the data to be MAR - as was described in Section \@ref(MDM). In the specific case of logistic regression - which was utulised in this study - listwise deletion could still give unbiased results even if the missingness isn’t MCAR, but only if the missing values are either in the predictor variables or in the outcome variable. From our EDA and missing data specification we observed that both predictor _and_ outcome variables contained missing data, hence the result were biased as well.

When listwise deletion is used on a dataset where the missingness isn’t MCAR, it will result in a bias in the regression coefficients, with standard errors that are too large. As the models in this study were logistic regression models, the regression coefficients were transformed into odds ratios instead. Another negative of listwise deletion is that it is wasteful, a lot of data goes unused. This is also the case in this study, as 41% of the cases were deleted. This might explain why the listwise deletion model has a lower $D$ value; there is just a lot less data that might not fit in the model. Another consequence of removing so much data from the dataset is that it becomes more difficult to find effects, this is a possible explanation for why the listwise deletion model had less significant predictors. 

Using mean imputation on a dataset where the missingness isn’t MCAR will give biased results and underestimated standard errors. It is indeed the case that the standard errors in the mean imputation model are lower than those in the listwise deletion model. As listwise deletion usually overestimates the standard errors, the real values are probably somewhere in between.

So as both methods were used on data that wasn't MCAR,  the created models were biased in multiple ways and thus weren't valid.

# Conclusion

- go back to papers, reflect hypo
- stuffs

# References

<div id="refs"></div>

# (APPENDIX) Appendix {-} 

# Appendix

```{r data-sum, echo=FALSE}
sumtable(data, title = "Summary statistics", fit.page = TRUE)
```

\newpage

```{r lw-model, echo = FALSE}
# Make table of the glm output
as_kable_extra(tbl_regression(fit_lw, exponentiate = TRUE, intercept = TRUE) %>%
  add_significance_stars(hide_p = FALSE), escape = FALSE, addtl_fmt = TRUE, caption = "Listwise deletion model", format = "latex", booktabs = TRUE, longtable = TRUE, linesep = "") %>%
  kableExtra::kable_styling(
    position = "center",
    latex_options = c("striped", "repeat_header"),
    stripe_color = "gray!15"
  )
```

\newpage

```{r mi-model, echo = FALSE}
# Make table of the glm output
as_kable_extra(tbl_regression(fit_mi, conf.level = 0.95, exponentiate = TRUE, intercept = TRUE) %>%
  add_significance_stars(hide_p = FALSE), escape = FALSE, addtl_fmt = TRUE, caption = "Mean imputation model", format = "latex", booktabs = TRUE, longtable = TRUE, linesep = "") %>%
  kableExtra::kable_styling(
    position = "center",
    latex_options = c("striped", "repeat_header"),
    stripe_color = "gray!15"
  )
```
